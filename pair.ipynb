{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pair.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMK2jqCCZtpPQ3ku+W2v1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbalzy/RecipeQA-FInal-Project-2470/blob/main/pair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPoK-Ir4nAfZ",
        "outputId": "2a7e281a-9df6-4ded-8b99-b1db88599223"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "import os\r\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\r\n",
        "!cp \"/content/gdrive/My Drive/Kaggle/kaggle.json\" ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Gb68udnGcs",
        "outputId": "c856c732-eeca-4292-da19-9703d099dc6c"
      },
      "source": [
        "!kaggle datasets download -d jeromeblanchet/recipeqa-nlp-dataset\r\n",
        "!unzip recipeqa-nlp-dataset.zip -d data/ > /dev/null\r\n",
        "\r\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading recipeqa-nlp-dataset.zip to /content\n",
            "100% 2.54G/2.55G [02:01<00:00, 23.0MB/s]\n",
            "100% 2.55G/2.55G [02:01<00:00, 22.5MB/s]\n",
            "--2020-12-09 11:59:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-12-09 11:59:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-12-09 11:59:50--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.17MB/s    in 6m 42s  \n",
            "\n",
            "2020-12-09 12:06:33 (2.04 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXjYra88nIAT"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from preprocessrecipeqa import *\r\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNqXBYyMAH4p"
      },
      "source": [
        "batch_size = 1\r\n",
        "(train_iter1, train_iter2, train_iter3, train_iter4), (test_iter1, test_iter2, test_iter3, test_iter4), (val_iter1, val_iter2, val_iter3, val_iter4), embedding_index, word_index = preprocess(batch_size)\r\n",
        "l_embed = get_embedding_layer(word_index, embedding_index)\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Vsl1-lXPyD"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jk6yckmGuV9",
        "outputId": "f2a19e0a-cadc-44c0-f84c-27d7ace1921a"
      },
      "source": [
        "for i, label in train_iter1:\r\n",
        "  for j in i[0]: print(j)\r\n",
        "  # print(i[0]['recipe_id'])\r\n",
        "  for k in i[0]['context']:\r\n",
        "    print(k['body'])\r\n",
        "    print(len(k['images']))\r\n",
        "  break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recipe_id\n",
            "context\n",
            "choice_list\n",
            "question\n",
            "[20192, 11837, 27206, 17641, 2590, 14579, 9782, 795, 12409, 11827, 10972, 19896, 3682, 23563, 19190, 28977, 6235, 21435, 4462, 1263, 14216, 3671, 9880, 14490, 18706, 795, 10972, 12571, 8229, 11827, 27206, 5989, 3452, 16444, 5191, 12984, 8921, 27044, 21594, 27032, 679, 27206, 11456, 4244, 6844, 16127, 11837, 9726, 12571, 18775, 16967, 17425, 11827, 12409, 3080, 10176, 20105, 27831, 27206, 17950, 15189, 10176, 24089, 27831, 9234, 12571, 2995, 25664, 21594, 16967, 24929, 9880, 7162, 1086, 2718, 10972, 12583, 21594, 27206, 7400, 11827, 22195, 11456, 7318, 12571, 17170, 16967, 3176, 10972, 25025, 16581, 28369, 1086, 27206, 16461, 9880, 4934, 2583, 21435, 10176, 855, 19342, 6844, 27206, 9172, 16967, 28139, 14799, 1486, 27233, 18584, 21594, 5913, 10176, 855, 5382, 19342, 18706, 16967, 8837, 27206, 7986, 23686, 27032, 17425, 3682, 28139, 11991, 19337, 21594, 17452, 21594, 25327, 16967, 28369, 7101, 3682, 12370, 9880, 3583, 9880, 2069, 13174, 23340, 795, 27206, 9548, 21435, 21066, 5941, 9880, 28977, 26074, 29184, 367, 7101, 11364, 795, 14579, 12571, 5979, 11605, 8229, 795, 27206, 9172, 16967, 14579, 23723, 15189, 10176, 12388, 10972, 14579, 23723, 2027, 27206, 16404, 29002, 9234, 27206, 24896, 19488, 12583, 2152, 25327, 14844, 18353, 22410, 1017, 5509, 22410, 26433, 5258, 27206, 9548, 21435, 2718, 10972, 21920, 9880, 21390, 29274, 12571, 21435, 11837, 10622, 11675, 10440, 23797, 16449, 17288, 10972, 10176, 16462, 19337, 21594, 23723, 11827, 2069, 28917, 28847, 25327, 4720, 12571, 14729, 11827, 28977, 2027, 18353, 14579, 27206, 21575, 795, 29274, 6260, 11827, 9056, 23776, 9782, 3682, 15489, 15189, 24221, 7101, 17055, 27206, 10488, 23132, 11827, 10622, 17089, 7398, 23197, 10518, 28307, 29274, 3887, 11827, 23797, 16449, 2583, 18583, 26657, 18317, 18595, 2514, 26429, 10284, 4462, 8599, 9880, 24453, 18709, 7101, 16462, 27206, 23213, 25267, 14059, 11827, 26328, 14140, 21263, 19488, 5509, 2718, 10972, 12583, 25730, 12388, 19548, 9495, 26429, 18583, 1419, 4462, 2027, 16449, 12388, 19548, 27206, 25267, 26328, 19447, 26429, 23030, 795, 26104, 4462, 26996, 9548, 9782, 10972, 12583, 5649, 21263, 10622, 19870, 20324, 2773, 23197, 795, 19548, 21594, 13045, 19548, 16449, 25327, 10176, 8888, 16468, 12571, 14729, 11827, 19190, 19548, 21594, 9782, 6429, 12571, 23132, 9782, 3682, 22335, 9880, 670, 7101, 17915, 25730, 16462, 21678, 27877, 13413, 12888, 28369, 7101, 3514, 10022, 4462, 14579, 9880, 12388, 7440, 7101, 14490, 8832, 10517, 15665, 5509, 4313, 16967, 3944, 20935, 22842, 7599, 25730, 21678, 11827, 27206, 11738, 24028, 9782, 24089, 28040, 22168, 14140, 12571, 22842, 9880, 7016, 14140, 12571, 3284, 9782, 12583, 25730, 12832, 5509, 10972, 17915, 25730, 16462, 9880, 29319, 28977, 3644, 24877, 10891, 12309, 7286, 27206, 9881, 10515, 24816, 2936, 15189, 7101, 9166, 24877, 18709, 11968, 7101, 21968, 3176, 18706, 16967, 9782, 3682, 24877, 18104, 21594, 28139, 21968, 7986, 795, 5382, 9507, 9234, 19481, 6533, 21594, 15197, 9782, 21197, 20192]\n",
            "1\n",
            "[3080, 3682, 26996, 6105, 26445, 16669, 12571, 23353, 13583, 18706, 11837, 9897, 11827, 17478, 9880, 4934, 28977, 6235, 2027, 4462, 20392, 12571, 18351, 19896, 12192, 18706, 10972, 10176, 21920, 3533, 3895, 12571, 12013, 11827, 26911, 28977, 21435, 9412, 9880, 9283, 21594, 12571, 17022, 11827, 28977, 2027, 21594, 12571, 26996, 9816, 3682, 24877, 21678, 10221, 3080, 16967, 3944, 11675, 23251, 13583, 27206, 21100, 16404, 29002, 10868, 18949, 24996, 27206, 26911, 18949, 27922, 10412, 27206, 9272, 5382, 10883, 2027, 5509, 12571, 24624, 9880, 25527, 3625, 2027, 16967, 9880, 14490, 11432, 10972, 12583, 9880, 29319, 28977, 21435, 21100, 20192, 3682, 27206, 17641, 17656, 9234, 15763, 12571, 17022, 11914, 11827, 12571, 21435, 11837, 26911, 21594, 28977, 2027, 9782, 3682, 29082, 2514, 5509, 18706, 11837, 24089, 24929, 9880, 21920, 5382, 1486, 26104, 21435, 10868, 14257, 25327, 8837, 12097, 3625, 7286, 11827, 28977, 13726, 18949, 3080, 11837, 98, 9792, 9880, 12571, 17418, 6567, 2718, 10972, 21920, 26104, 4462, 26996, 2514, 10972, 12583, 24089, 11364, 12571, 18595, 26104, 9880, 14216, 19896, 474, 25730, 21920, 17418, 9880, 4934, 9782, 18949, 16444, 2583, 29002, 27237, 3664, 15974, 23522, 21435, 19190, 11120, 21920, 9880, 12387, 21263, 9782, 26237, 10477, 8043, 7101, 3682, 5509, 5791, 14140, 21263, 21888, 17532, 13583, 7101, 10176, 4420, 5191, 11326, 26237, 15189, 27184, 9880, 17818, 28904, 22822, 27206, 21549, 11827, 2514, 21888, 14257, 9782, 26429, 9880, 15187, 15764, 5805, 795, 10622, 18949, 7101, 22059, 12388, 19548, 18949, 21678, 10440, 18949, 10972, 12583, 10927, 13791, 12571, 10440, 16967, 27206, 24896, 8355, 16839, 9782, 12583, 8837, 22297, 18949, 15614, 11827, 27206, 6147, 3038, 24028, 10440, 16967, 21387, 9880, 9782, 10284, 21594, 17266, 2718, 28977, 9782, 10517, 17434, 11827, 12363, 21263, 16166, 7299, 10176, 27831, 15220, 7699, 25363, 27206, 3625, 2027, 27233, 3583, 16444, 9782, 22822, 19548, 14140, 24054, 27822, 7623, 8043, 7101, 3682, 3055, 9880, 17152, 2718, 10972, 12583, 7162, 18706, 14490, 2600, 14490, 25327, 9782, 6429, 20637, 7101, 16525, 14140, 18706, 7016, 14140, 18706, 21594, 12571, 21546, 10176, 28449, 17055, 18706, 4853, 9880, 3998, 28438, 9782, 3682, 24877, 14172, 8764, 2718, 7101, 21920, 12571, 17418, 21594, 15662, 9880, 14490, 5509, 7101, 10176, 28139, 3612, 27206, 11334, 28575, 9880, 12571, 10464, 13583, 16967, 8311, 18317, 17870, 7101, 17055, 21594, 2562, 2718, 25327, 28575, 16967, 1881, 2297, 12571, 10440, 10972, 10176, 2600, 28449, 21920, 9880, 17152, 18706, 13174, 4794, 2718, 10972, 21920, 10284, 13583, 12583, 16971, 21594, 23913, 8502, 18706, 9880, 18268, 1246, 21594, 28119, 2718, 10972, 12583, 13795, 19548, 27206, 9463, 21594, 17466, 1714, 17870, 7101, 12583, 29319, 27206, 13332, 26104, 7688, 9782, 6429, 5382, 1486, 20637, 16967, 3284, 10972, 12583, 28139, 20391, 6410, 21100, 28977, 21435, 16967, 20324, 6410, 21678, 11827, 21263, 21779, 21594, 16212, 3682, 16950, 16444, 3284, 18706, 8837, 802, 18949, 27206, 22954, 24089, 11341, 28977, 9782, 16444, 4313, 14662, 5769, 7101, 12583, 17076, 14140, 12571, 1223, 9782, 12583, 22434, 24877, 17658, 18949, 7101, 22434, 9880, 5762, 27206, 21549, 11827, 423, 16660, 14140, 12571, 4313, 11827, 27206, 26292, 8832, 7101, 8837, 6429, 9880, 7016, 21594, 27831, 21276, 14140, 24811, 10972, 12583, 7286, 25327, 9880, 28977, 28835, 29319, 19548, 20464, 795, 10972, 795, 11603, 16444, 27206, 24481, 15375, 29319, 27206, 7710, 6049, 1881, 10972, 25025, 9880, 19447, 27206, 26292, 12789, 27206, 17641, 28307, 11827, 5092, 14140, 12571, 6049, 12571, 9782, 10176, 6429, 17101, 13174, 12571, 5092, 13045, 10972, 27206, 6049, 795, 28977, 26292, 9782, 3682, 15489, 5509, 1203, 21594, 21066, 21263, 10622, 643, 23797, 16449, 23197, 7398, 26292, 7154, 13677, 17288, 9880, 21263, 19488, 10176, 2600, 7254, 14094, 28977, 2069, 5146, 18706, 10176, 16577, 5382, 11827, 21263, 16825]\n",
            "4\n",
            "[2718, 10972, 3682, 2600, 8784, 14140, 19282, 25327, 15614, 9199, 15840, 9880, 12571, 13014, 20389, 25327, 16967, 12571, 15614, 13583, 4720, 27233, 3583, 10477, 15189, 16967, 6897, 11328, 18706, 11837, 28904, 21875, 9880, 23181, 6607, 29002, 4794, 26104, 26429, 27206, 21435, 15189, 24840, 12134, 27206, 26550, 8832, 12571, 4529, 9190, 9880, 22822, 9782, 16967, 795, 2027, 5509, 25327, 15614, 11827, 18706, 27777, 27831, 7273, 2718, 10972, 25025, 9880, 21920, 19342, 2718, 10972, 13413, 17915, 25730, 25025, 9880, 14490, 18706, 10972, 12583, 7623, 3492, 14216, 16444, 27799, 9880, 14835, 21594, 25274, 20192, 11837, 27206, 17641, 2994, 9880, 29319, 18706, 29274, 3055, 795, 5382, 12577, 9507, 8439, 20192, 15574, 27206, 9463, 17870, 10972, 10176, 27831, 26697, 12571, 13097, 27206, 26480, 4462, 5509, 14351, 19925, 15197, 28977, 21435, 3080, 25327, 10176, 29319, 28448, 24806, 16444, 12571, 28575, 21594, 12571, 2510, 5509, 13583, 9234, 11605, 10880, 22323, 10176, 2600, 27831, 5791, 10972, 14490, 2600, 25025, 9880, 15974, 28977, 21435, 14140, 2583, 6381, 2600, 7254, 10176, 18706, 13279, 28448, 12527, 23290, 18706, 16967, 8837, 2600, 24896, 795, 12571, 2027, 28369, 22323, 16967, 18025, 10972, 12583, 7286, 12571, 11207, 4796, 28448, 28449, 19282, 10972, 10176, 14162, 25025, 9880, 14702, 12571, 21435, 22168, 5509, 13583, 18949, 21678, 11827, 12571, 26012, 7154, 12571, 11180, 18949, 27922, 21920, 19022, 0, 1968, 23933, 10054, 25506, 11827, 9056, 20826, 1428, 23933, 16534, 17726, 11962, 13316, 11962, 11727, 1714, 16962, 12571, 10880, 6044, 21594, 14162, 19925, 14461, 12571, 13014, 24878, 29319, 1465, 10972, 3682, 14140, 12571, 4313, 21594, 13583, 10972, 20464, 6044, 18706, 9412, 4711, 14662, 14140, 12444, 4462, 7352, 10972, 12583, 26954, 16971, 18754, 7032, 21594, 3765, 12571, 21435, 8832, 2718, 10972, 25025, 12571, 3765, 9880, 29319, 12657, 10972, 10176, 16462, 9880, 13363, 12571, 10613, 10477, 19494, 25327, 6307, 29178, 5165, 2600, 16336, 1714, 3895, 6607, 28575, 21594, 14162, 28369, 18706, 11837, 4711, 22782, 27206, 28278, 7260, 3895, 12571, 3765, 9880, 24553, 12571, 10613, 11968, 7273, 7324, 19022, 13413, 18709, 11968, 10972, 21920, 19845, 12571, 24649, 17330, 12571, 1282, 11827, 12571, 7195, 7554, 9880, 12571, 0, 12571, 7554, 25025, 9880, 27831, 18949, 26617, 25241, 18949, 27922, 14162, 4934, 12571, 10833, 15122, 12571, 28196, 12387, 5805, 12571, 20084, 4769, 20853, 24776, 2297, 12571, 14227, 20250, 12571, 20084, 14227, 22168, 27206, 19232, 21594, 13483, 27206, 10886, 5805, 18706, 3019, 6803, 9880, 7162, 14633, 8319, 22168, 14162, 24553, 12571, 15515, 27674, 10972, 25025, 9880, 24553, 29274, 12571, 28418, 13330, 21594, 7531, 3588, 12571, 9538, 10972, 25025, 9880, 22822, 23311, 28977, 423, 21594, 27831, 24877, 22672, 2600, 9880, 20493, 2583, 11827, 12571, 10352, 4462, 26236, 8105, 17466, 9816, 1714, 10176, 2600, 7324, 8311, 15122, 27206, 11836, 18853, 12387, 16468, 12571, 19184, 28632, 12571, 10833, 2297, 26996, 11939, 7324, 5191, 22758, 21594, 14162, 11605, 5191, 2297, 12571, 11953, 23776, 9199, 22360, 13583, 21102, 15965, 12571, 19983, 5408, 9234, 12571, 9056, 15541, 23776, 9234, 12571, 28970, 25911, 19762, 0, 25333, 10715]\n",
            "4\n",
            "[11968, 10972, 21920, 20903, 12571, 23776, 11827, 19342, 21594, 2252, 16839, 10972, 1169, 25025, 9880, 28339, 19548, 10972, 12583, 26954, 18367, 21594, 17055, 19548, 18949, 16967, 6844, 7101, 24377, 27206, 21549, 14799, 28369, 2661, 21594, 21920, 27206, 9056, 4584, 6044, 10972, 19925, 27962, 5191, 12387, 21594, 10517, 1474, 11456, 11328, 9880, 18138, 12571, 23776, 14140, 21594, 13583, 10176, 18138, 14140, 28977, 13667, 2718, 10972, 3682, 26697, 25327, 14140, 7352, 21594, 18706, 9405, 11727, 29274, 10880, 17870, 10972, 3682, 10972, 10176, 2600, 16462, 9880, 12789, 12571, 1474, 14140, 12571, 13667, 26954, 29319, 1465, 7101, 3514, 21337, 18317, 2514, 28339, 14272, 23723, 2027, 16456, 1714, 7462, 976, 7462, 1658, 7462, 28339, 17525, 2431, 21845, 14140, 12571, 21741, 11827, 12379, 8871, 17466, 11827, 12571, 28339, 2297, 12571, 2027, 29184, 12571, 11836, 795, 19342, 10972, 17915, 25730, 16462, 9880, 15737, 2960, 28977, 23776, 14140, 12571, 7008, 28339, 12789, 27206, 3567, 20055, 14844, 9234, 19329, 9880, 29319, 1465, 18706, 474, 25730, 18223, 22168, 11827, 12571, 28339, 6502, 18706, 14140, 11727, 1714, 795, 4418, 14140, 27206, 25284, 14140, 13667, 2718, 12571, 15841, 19698, 16967, 2600, 11727, 10972, 12583, 6502, 18706, 795, 14799, 2718, 10972, 25231, 12571, 28339, 10176, 26954, 27831, 953, 13307, 18007, 14140, 1714, 795, 26996, 9052, 28070, 12571, 2027, 2718, 18706, 11837, 28441, 13413, 18429, 13307, 15813, 21594, 6502, 9880, 18007, 14140, 1714, 795, 13126, 9052, 10626, 6844, 12309, 21920, 28904, 1770, 2583, 21105, 11827, 24028, 3459, 19344, 28369, 12309, 11605, 27206, 21435, 12309, 3682, 9928, 16520, 795, 26996, 4870, 4418, 12780, 29274, 12571, 2027, 18488, 24667, 17288, 21594, 27689, 12309, 17915, 25730, 10517, 5805, 9880, 21678, 27700, 795, 9507, 9234, 12780, 18488, 21594, 24667, 21197, 20192]\n",
            "1\n",
            "[25327, 16967, 12571, 7209, 15614, 15824, 10440, 12192, 19342, 16967, 14579, 12571, 27233, 14896, 7688, 14140, 12571, 1057, 12309, 28139, 336, 27206, 4870, 25872, 11827, 2027, 18353, 11968, 12379, 19342, 8599, 24667, 21594, 18706, 16967, 6607, 29274, 10880, 21183, 14140, 23353, 28369, 6633, 8439, 336, 27619, 18317, 24028, 9463, 12309, 28139, 9780, 13174, 25527, 27206, 10331, 4462, 26996, 12309, 29307, 27206, 10125, 22168, 11827, 6607, 1017, 12454, 4414, 21594, 27206, 6952, 17342, 2718, 10972, 25025, 9880, 8439, 25327, 0, 21197, 20192, 19925, 27206, 17257, 14140, 28977, 13253, 15122, 10354, 1790, 4462, 13308, 7949, 18706, 11837, 2154, 2718, 18706, 11837, 27206, 98, 21556, 18949, 18706, 11837, 12571, 336, 10972, 25025, 12309, 15030, 22822, 27206, 11683, 11827, 1714, 20324, 24028, 10125, 21594, 7630, 12571, 19615, 14140, 795, 27206, 98, 22195, 336, 2718, 10972, 25025, 10972, 12583, 12789, 27206, 21015, 11827, 11432, 21845, 10972, 26429, 9234, 12571, 19342, 8832, 12309, 22848, 2600, 9880, 12789, 14633, 3671, 9234, 18706, 18706, 16967, 14292, 24896, 11328, 9234, 15005, 6235, 9463, 12571, 23776, 11827, 2027, 9234, 12571, 21508, 20080, 28977, 336, 13800, 26772, 28977, 336, 13800, 14140, 12571, 21741, 11827, 24028, 27134, 12789, 12571, 10423, 9234, 19329, 11827, 12571, 4414, 10972, 25025, 12571, 23864, 16163, 12571, 4414, 9880, 27831, 19337, 21594, 16634, 2844, 12571, 7949, 10972, 13015, 9268, 22822, 12571, 17257, 10323, 795, 18949, 2981, 18949, 18706, 868, 795, 12571, 2027, 9880, 8282, 12571, 6567, 23864, 16444, 27206, 2027, 4049, 14140, 12571, 21741, 11827, 19342, 18706, 27687, 9880, 27831, 14579, 16634, 14140, 12571, 8033, 15189, 10176, 23311, 14579, 9052, 11827, 17478, 10972, 10176, 21920, 9880, 18260, 18706, 24832, 24832, 5356, 9880, 29319, 1465, 18706, 11837, 27003, 18709, 17055, 18949, 21678, 18949, 10972, 12583, 14883, 16755, 18706, 11837, 28441, 4711, 21594, 12387, 12571, 2896, 2297, 2995, 14395, 9880, 23564, 10972, 3048, 25730, 21920, 9880, 21390, 19342, 18317, 12571, 9984, 29274, 6500]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCgaF-bDIgg_"
      },
      "source": [
        "def define_model():\r\n",
        "  img_inputs = keras.Input(shape=(224, 224, 3))\r\n",
        "  l1 = keras.layers.Conv2D(filters = 64, kernel_size = 5, strides=(2, 2), padding='same')\r\n",
        "  x = l1(img_inputs)\r\n",
        "  l2 = keras.layers.Conv2D(filters = 64, kernel_size = 5, strides=(2, 2), padding='same')\r\n",
        "  x = l2(x)\r\n",
        "  l3 = keras.layers.Conv2D(filters = 64, kernel_size = 5, strides=(2, 2), padding='same')\r\n",
        "  x = l3(x)\r\n",
        "  l4 = keras.layers.Conv2D(filters = 64, kernel_size = 5, strides=(2, 2), padding='same')\r\n",
        "  x = l4(x)\r\n",
        "  flatten = keras.layers.Flatten()\r\n",
        "  x = flatten(x)\r\n",
        "  densex = keras.layers.Dense(100,activation='tanh')\r\n",
        "  x = densex(x)\r\n",
        "  text_inputs = keras.Input(shape = (None,100))\r\n",
        "  lstm = tf.keras.layers.LSTM(100)\r\n",
        "\r\n",
        "  densey =tf.keras.layers.Dense(100,activation='tanh')\r\n",
        "  y = densey(lstm(text_inputs))\r\n",
        "  \r\n",
        "  concat = keras.layers.Concatenate()\r\n",
        "  fc1 = keras.layers.Dense(500,activation = 'relu')\r\n",
        "  z = fc1(concat([x,y]))\r\n",
        "  fc2 = keras.layers.Dense(500,activation = 'relu')\r\n",
        "  z = fc2(z)\r\n",
        "  fc3 = keras.layers.Dense(2,activation = 'softmax')\r\n",
        "  outputs = fc3(z)\r\n",
        "  model = tf.keras.Model(inputs=[text_inputs,img_inputs], outputs=outputs)\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam')\r\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Lt9WOSLc0t"
      },
      "source": [
        "model = define_model()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYz8h7wpRcNC",
        "outputId": "a3247135-bb55-4fd0-f13f-7ce020376fd2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 112, 112, 64) 4864        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 56, 56, 64)   102464      conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 64)   102464      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 14, 14, 64)   102464      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, None, 100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 12544)        0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 100)          80400       input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 100)          1254500     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 100)          10100       lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           dense_9[0][0]                    \n",
            "                                                                 dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 500)          100500      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 500)          250500      dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 2)            1002        dense_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,009,258\n",
            "Trainable params: 2,009,258\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEBVWErWLySm",
        "outputId": "b626ba89-7600-46fb-eedf-67dbf2dd95aa"
      },
      "source": [
        "model.predict([l_embed(np.ones([1,10])),np.ones([1,224,224,3])])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52147526, 0.47852474]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKm17I9ECHm7",
        "outputId": "1ed17a3d-566b-45f9-875e-321d7f8753fa"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.361645576660521e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "Ubq1jeVwGWmE",
        "outputId": "26fc7004-2356-47c0-b5ec-29febad5d992"
      },
      "source": [
        "for i, label in train_iter1:\r\n",
        "  for batch in i: \r\n",
        "    if len(batch['context'])==1:\r\n",
        "      continue\r\n",
        "  # print(i[0]['recipe_id'])\r\n",
        "    for k in range(len(batch['context'])):\r\n",
        "      # print(k['body'])\r\n",
        "      loss = 0\r\n",
        "      context = batch['context'][k]\r\n",
        "      if len(context['images'])==0:\r\n",
        "        continue\r\n",
        "      input_text = l_embed(tf.tile([context['body']],[len(context['images']),1]))\r\n",
        "      input_images = tf.convert_to_tensor (context['images'])\r\n",
        "      labels = np.ones([len(input_text)])\r\n",
        "      if input_text.shape[1]!=0:\r\n",
        "        loss= model.train_on_batch([input_text,input_images],labels)\r\n",
        "        # print(model.predict([input_text,input_images]))\r\n",
        "      \r\n",
        "      j = random.randint(0,len(batch['context'])-1)\r\n",
        "      while j==k:\r\n",
        "        j = random.randint(0,len(batch['context'])-1)\r\n",
        "      fake_context = batch['context'][j]\r\n",
        "      input_text2 = l_embed(tf.tile([fake_context['body']],[len(context['images']),1]))\r\n",
        "      labels2 = np.zeros([len(input_text)])\r\n",
        "      if input_text2.shape[1]!=0:\r\n",
        "        loss+=model.train_on_batch([input_text2,input_images],labels2)\r\n",
        "        loss/=2\r\n",
        "      print(loss)\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7309737205505371\n",
            "0.6982189118862152\n",
            "0.7037436068058014\n",
            "0.7099738717079163\n",
            "0.7297621369361877\n",
            "0.7126275599002838\n",
            "0.7170794606208801\n",
            "0.7091774642467499\n",
            "0.7046544551849365\n",
            "0.7082193791866302\n",
            "0.7040002644062042\n",
            "0.6899984180927277\n",
            "0.6935310661792755\n",
            "0.7080830931663513\n",
            "0.7070668935775757\n",
            "0.6980837285518646\n",
            "0.6991521120071411\n",
            "0.6999296844005585\n",
            "0.7040022313594818\n",
            "0.7035335600376129\n",
            "0.6997336149215698\n",
            "0.7037566304206848\n",
            "0.6932750940322876\n",
            "0.7081494927406311\n",
            "0.7187564969062805\n",
            "0.6985742151737213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-50f9d9b212db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print(model.predict([input_text,input_images]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[1;32m   1692\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m                                                     class_weight)\n\u001b[0m\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0;32m--> 387\u001b[0;31m                                    graph_rewrite_configs)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;31m# (3) Apply autotune options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[1;32m   4398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4399\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4400\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4401\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[0;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   3946\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3947\u001b[0m         \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimization_configs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3948\u001b[0;31m         optimization_configs)\n\u001b[0m\u001b[1;32m   3949\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "o8UQuBh-c_KQ",
        "outputId": "7acb62e6-6ce0-4fa1-a896-05b1bb9c8925"
      },
      "source": [
        "t=0\r\n",
        "a=0\r\n",
        "for i, label in val_iter1:\r\n",
        "  for batch in i: \r\n",
        "  # print(i[0]['recipe_id'])\r\n",
        "    for k in range(len(batch['context'])):\r\n",
        "      loss = 0\r\n",
        "      context = batch['context'][k]\r\n",
        "      if len(context['images'])==0:\r\n",
        "        continue\r\n",
        "      input_text = l_embed(tf.tile([context['body']],[len(context['images']),1]))\r\n",
        "      input_images = tf.convert_to_tensor (context['images'])\r\n",
        "      if input_text.shape[1]!=0:\r\n",
        "        logits = (model.predict([input_text,input_images]))\r\n",
        "        for i in logits:\r\n",
        "          t+=1\r\n",
        "          if i[1]>0.5:\r\n",
        "            a+=1\r\n",
        "      # j = random.randint(0,len(batch['context'])-1)\r\n",
        "      # while j==k:\r\n",
        "      #   j = random.randint(0,len(batch['context'])-1)\r\n",
        "      # fake_context = batch['context'][j]\r\n",
        "      # input_text2 = l_embed(tf.tile([fake_context['body']],[len(context['images']),1]))\r\n",
        "      # if input_text2.shape[1]!=0:\r\n",
        "      #   logits=model.predict([input_text2,input_images])\r\n",
        "      #   for i in logits:\r\n",
        "      #     t+=1\r\n",
        "      #     if i[1]<0.5:\r\n",
        "      #       a+=1\r\n",
        "  print(a/t)\r\n",
        "        # print(model.predict([input_text,input_images]))\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10526315789473684\n",
            "0.2\n",
            "0.20689655172413793\n",
            "0.2\n",
            "0.21176470588235294\n",
            "0.23333333333333334\n",
            "0.22448979591836735\n",
            "0.2018348623853211\n",
            "0.19469026548672566\n",
            "0.18253968253968253\n",
            "0.2\n",
            "0.20134228187919462\n",
            "0.20253164556962025\n",
            "0.21176470588235294\n",
            "0.21264367816091953\n",
            "0.21978021978021978\n",
            "0.21428571428571427\n",
            "0.2107843137254902\n",
            "0.215311004784689\n",
            "0.2145922746781116\n",
            "0.22709163346613545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f27c088c2ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_iter1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# print(i[0]['recipe_id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/preprocessrecipeqa.py\u001b[0m in \u001b[0;36mdata_iter\u001b[0;34m(batch_size, dataset, task, split)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m           \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/images/images-qa/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/images-qa/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"visual_cloze\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/preprocessrecipeqa.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m           \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/images/images-qa/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/images-qa/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"visual_cloze\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/preprocessrecipeqa.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Convert image to normalized float [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;31m# resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mconvert_image_dtype\u001b[0;34m(image, dtype, saturate, name)\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;31m# Converting from float: first scale, then cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    507\u001b[0m   \"\"\"\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6161\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6162\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6163\u001b[0;31m         x, y)\n\u001b[0m\u001b[1;32m   6164\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}