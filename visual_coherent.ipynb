{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visual coherent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfCx4VGnK+6paBbyoIKvtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbalzy/RecipeQA-FInal-Project-2470/blob/main/visual_coherent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUzioZhuNwEl"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "  def __init__(self, window_sz, vocab_sz, num_images, image_shape):\n",
        "    self.window_size = window_sz\n",
        "    self.vocab_size = vocab_sz\n",
        "    self.num_images = num_images\n",
        "    self.image_shape = image_shape\n",
        "    \n",
        "\n",
        "    self.image_conv1 = tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, strides=(1, 1), padding='valid')\n",
        "    self.image_conv2 = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides=(1, 1), padding='valid')\n",
        "    self.image_conv3 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides=(1, 1), padding='valid')\n",
        "    self.image_dense = tf.keras.layers.dense(units = 100)\n",
        "\n",
        "    self.word_embedding = tf.Variable(tf.random.truncated_normal([self.english_vocab_size, self.embedding_size], stddev = 0.1))\n",
        "    self.encoder = tf.keras.layers.GRU(units = 100, return_sequences=True, return_state=True)\n",
        "    self.text_dense = tf.keras.layers.dense(units = 100)\n",
        "\n",
        "    self.text_image_embedding1 = tf.keras.layers.dense(units = 200, activation = \"relu\")\n",
        "    self.text_image_embedding2 = tf.keras.layers.dense(units = 100)\n",
        "\n",
        "    self.class_dense1 = tf.keras.layers.dense(units = 50, activation = \"relu\")\n",
        "    self.class_dense2 = tf.keras.layers.dense(units = 20, activation = \"relu\")\n",
        "    self.class_dense3 = tf.keras.layers.dense(units = 4)\n",
        "\n",
        "  def call(self, query_text, choice_image):\n",
        "\n",
        "    choice_token = self.image_conv1(choice_image[0])\n",
        "    choice_token = self.image_conv2(choice_token)\n",
        "    choice_token = self.image_conv3(choice_token)\n",
        "    choice0_embedding = self.image_dense(choice_token)\n",
        "\n",
        "    choice_token = self.image_conv1(choice_image[1])\n",
        "    choice_token = self.image_conv2(choice_token)\n",
        "    choice_token = self.image_conv3(choice_token)\n",
        "    choice1_embedding = self.image_dense(choice_token)\n",
        "\n",
        "    choice_token = self.image_conv1(choice_image[2])\n",
        "    choice_token = self.image_conv2(choice_token)\n",
        "    choice_token = self.image_conv3(choice_token)\n",
        "    choice2_embedding = self.image_dense(choice_token)\n",
        "\n",
        "    choice_token = self.image_conv1(choice_image[3])\n",
        "    choice_token = self.image_conv2(choice_token)\n",
        "    choice_token = self.image_conv3(choice_token)\n",
        "    choice3_embedding = self.image_dense(choice_token)\n",
        "\n",
        "    #query word embedding\n",
        "    embedding = tf.nn.embedding_lookup(self.word_embedding, query_text)\n",
        "    final_output, final_state = self.encoder(embedding, initial_state = None)\n",
        "    text_embedding = self.text_dense(final_output)\n",
        "\n",
        "    #create image_word embedding for choice 0\n",
        "    token = tf.stack(choice0_embedding, text_embedding)\n",
        "    token = self.text_image_embedding1(token)\n",
        "    choice0_embedding = self.text_image_embedding2(token)\n",
        "\n",
        "     #create image_word embedding for choice 1\n",
        "    token = tf.stack(choice1_embedding, text_embedding)\n",
        "    token = self.text_image_embedding1(token)\n",
        "    choice1_embedding = self.text_image_embedding2(token)\n",
        "\n",
        "     #create image_word embedding for choice 2\n",
        "    token = tf.stack(choice2_embedding, text_embedding)\n",
        "    token = self.text_image_embedding1(token)\n",
        "    choice2_embedding = self.text_image_embedding2(token)\n",
        "\n",
        "     #create image_word embedding for choice 3\n",
        "    token = tf.stack(choice3_embedding, text_embedding)\n",
        "    token = self.text_image_embedding1(token)\n",
        "    choice3_embedding = self.text_image_embedding2(token)\n",
        "\n",
        "    token = tf.concat(choice0_embedding, choice1_embedding, choice2_embedding, choice3_embedding)\n",
        "    token = self.class_dense1(token)\n",
        "    token = self.class_dense2(token)\n",
        "    logit = self.class_dense3(token)\n",
        "    \n",
        "  def loss(self, probs, labels):\n",
        "    return  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}