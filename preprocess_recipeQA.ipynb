{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "preprocess-recipeQA",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbalzy/RecipeQA-FInal-Project-2470/blob/main/preprocess_recipeQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc_xt_0EnLjC",
        "outputId": "06ec66af-d4a5-4703-b546-016ced00dc3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!cp \"/content/gdrive/My Drive/Kaggle/kaggle.json\" ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuqEJgQvnOTn",
        "outputId": "4fb2fed6-1fde-4e30-a7be-e45242ada7a5"
      },
      "source": [
        "!kaggle datasets download -d jeromeblanchet/recipeqa-nlp-dataset\n",
        "!unzip recipeqa-nlp-dataset.zip -d data/ > /dev/null\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading recipeqa-nlp-dataset.zip to /content\n",
            "100% 2.54G/2.55G [01:29<00:00, 25.8MB/s]\n",
            "100% 2.55G/2.55G [01:29<00:00, 30.4MB/s]\n",
            "--2020-11-30 14:42:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-11-30 14:42:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-11-30 14:42:39--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.25MB/s    in 6m 29s  \n",
            "\n",
            "2020-11-30 14:49:09 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhO1dbGLmEj6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOw7DHwq_Qg7"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "\n",
        "def read_file(file_name):\n",
        "  with open(file_name, encoding='utf-8') as f:\n",
        "    data = json.load(f)['data']\n",
        "  textual_cloze = [item for item in data if item[\"task\"]==\"textual_cloze\"]\n",
        "  visual_cloze = [item for item in data if item[\"task\"]==\"visual_cloze\"]\n",
        "  visual_coherence = [item for item in data if item[\"task\"]==\"visual_coherence\"]\n",
        "  visual_ordering = [item for item in data if item[\"task\"]==\"visual_ordering\"]\n",
        "  return textual_cloze, visual_cloze, visual_coherence, visual_ordering"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoeEEph3IGC5"
      },
      "source": [
        "def tokenize(word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGsi8uMkB3vJ"
      },
      "source": [
        "def delete_keys(dataset):\n",
        "  match = re.compile('[^A-Za-z]')\n",
        "  s = \"\"\n",
        "  if not dataset[0][\"task\"]==\"textual_cloze\":\n",
        "    for data in dataset:\n",
        "      for step in data['context']:\n",
        "        step['title'] = re.sub(match,' ', step['title']).lower()\n",
        "        step['body'] = re.sub(match,' ', step['body']).lower()\n",
        "        s += step['title']+ step['body']\n",
        "  else:\n",
        "    for data in dataset:\n",
        "      for step in data['context']:\n",
        "        step['body'] = re.sub(match,' ', step['body']).lower()\n",
        "        s += step['body']\n",
        "      for i in range(len(data['choice_list'])):\n",
        "        data['choice_list'][i] = re.sub(match,' ', data['choice_list'][i]).lower()\n",
        "        s += data['choice_list'][i]\n",
        "      for i in range(len(data['question'])):\n",
        "        data['question'][i] = re.sub(match,' ', data['question'][i]).lower()\n",
        "        s += data['question'][i]\n",
        "  if (dataset[0][\"task\"]==\"visual_coherence\"):\n",
        "    [data.pop(\"question\") for data in dataset]\n",
        "  if (dataset[0][\"task\"]==\"visual_ordering\"):\n",
        "    [data.pop(\"question\") for data in dataset]\n",
        "    for data in dataset:\n",
        "      order = data[\"choice_list\"][0]\n",
        "      data[\"image_list\"] = {0:order[0], 1:order[1], 2:order[2], 3:order[3]}\n",
        "      img2ind = {v:k for k,v in data[\"image_list\"].items()}\n",
        "      data[\"choice_list\"]=[[img2ind[img] for img in choice] for choice in data[\"choice_list\"]]\n",
        "  [[data.pop(key,None) for key in [\"context_modality\", \"split\", \"qid\", \"question_modality\", \"task\", \"question_text\"]] for data in dataset]\n",
        "  [[[step.pop(key) for key in [\"id\",\"videos\"]] for step in data['context']] for data in dataset]\n",
        "  \n",
        "#  print(json.dumps(dataset[0], indent=4))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHzzLeWAa8bH"
      },
      "source": [
        "def load_image(file_path):\n",
        "# Load image\n",
        "  image = tf.io.decode_jpeg(tf.io.read_file(file_path),channels=3)\n",
        "# Convert image to normalized float [0, 1]\n",
        "  image = tf.image.convert_image_dtype(image,tf.float32)\n",
        "# resize image\n",
        "  image = tf.image.resize(image, [256,256])\n",
        "# Rescale data to range (-1, 1)\n",
        "  image = (image - 0.5) * 2\n",
        "  return image"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vxBRb4lXzXa"
      },
      "source": [
        "from copy import deepcopy\n",
        "def data_iter(batch_size, dataset, task, split):\n",
        "  num_input = len(dataset)\n",
        "  # np.random.shuffle(dataset)\n",
        "  for i in range(num_input // batch_size):\n",
        "    Xs = deepcopy(dataset[i*batch_size:(i+1)*batch_size])\n",
        "    Ys = [item.pop(\"answer\") for item in Xs]\n",
        "    if task==\"textual_cloze\":\n",
        "      for X in Xs:\n",
        "        for step in X[\"context\"]:\n",
        "          step[\"images\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in step[\"images\"]]\n",
        "    if task==\"visual_cloze\":\n",
        "      for X in Xs:\n",
        "        X[\"choice_list\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in X[\"choice_list\"]]\n",
        "        X[\"question\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) if not item==\"@placeholder\" else \"@placeholder\"  for item in X[\"question\"]]\n",
        "    if task==\"visual_coherence\":\n",
        "      for X in Xs:\n",
        "        X[\"choice_list\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in X[\"choice_list\"]]\n",
        "    if task==\"visual_ordering\":\n",
        "      for X in Xs:\n",
        "        for k,v in X[\"image_list\"].items():\n",
        "          X[\"image_list\"][k] = load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+X[\"image_list\"][k])\n",
        "    yield Xs, Ys\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifG_snpYmAsL"
      },
      "source": [
        "def load_embeddings(path_to_glove_file = '/content/glove.6B.100d.txt'):\n",
        "  embedding_index = {}\n",
        "  with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "      embedding_index[word] = coefs\n",
        "  return embedding_index\n",
        "\n",
        "def get_embedding_layer(voc, word_index, embeddings_index, embedding_dim = 100):\n",
        "  num_tokens = len(word_index) + 2\n",
        "  embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "  for word, i in word.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  embedding_layer = tf.keras.layers.Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "  )\n",
        "  return embedding_layer"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdayD-JWf_mT"
      },
      "source": [
        "def preprocess(batch_size, split):\n",
        "  textual_cloze, visual_cloze, visual_coherence, visual_ordering=read_file(\"data/\"+split+\" recipeqa.json\")\n",
        "  delete_keys(textual_cloze)\n",
        "  delete_keys(visual_cloze)\n",
        "  delete_keys(visual_coherence)\n",
        "  delete_keys(visual_ordering)\n",
        "  textual_cloze_iter = data_iter(batch_size, textual_cloze, \"textual_cloze\", split)\n",
        "  visual_cloze_iter = data_iter(batch_size, visual_cloze, \"visual_cloze\", split)\n",
        "  visual_coherence_iter = data_iter(batch_size, visual_coherence, \"visual_coherence\", split)\n",
        "  visual_ordering_iter = data_iter(batch_size, visual_ordering, \"visual_ordering\", split)\n",
        "  return textual_cloze_iter, visual_cloze_iter, visual_coherence_iter, visual_ordering_iter"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhE9wKi1rpt7"
      },
      "source": [
        "def main():\n",
        "  batch_size = 50\n",
        "  train_it1, train_it2, train_it3, train_it4 = preprocess(batch_size, \"train\")\n",
        "  dic = {'unk':0, 'pad':1}\n",
        "  # for i in train_it1:\n",
        "  #   print(i['context'])\n",
        "  #   for batch in i\n",
        "  #   for j in i['context']:\n",
        "  #     j['body']=j['body'].split()\n",
        "  #     j['body']=[k for k in j['body'] if k!='']\n",
        "  #   for j in i['choice_list']:\n",
        "  #     j['body']=[k for k in j if k!='']\n",
        "  #   for j in i['question']:\n",
        "  #     j['body']=[k for k in j if k!='']\n",
        "  \n",
        "  # word_index = words_to_index([train_it1, train_it2, train_it3, train_it4])\n",
        "  test_it1, test_it2, test_it3, test_it4 = preprocess(batch_size, \"test\")\n",
        "  val_it1, val_it2, val_it3, val_it4 = preprocess(batch_size, \"val\")\n",
        "  # Usage:\n",
        "  for Xs, Ys in train_it1:\n",
        "    print(json.dumps(Xs[0], indent=4, default=lambda x:\"tf_tensor\"))\n",
        "    print(Ys[0])\n",
        "    break"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oHi57yldxI15",
        "outputId": "036eb3e4-3aab-4fbe-9a0b-93f0158d003d"
      },
      "source": [
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-b985c2114c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-178-41dfc4555e66>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_it1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_it2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_it3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_it4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'unk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pad'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_it1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoJWUXYMrvS"
      },
      "source": [
        "train_it1, train_it2, train_it3, train_it4 = preprocess(10, \"train\")"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWVcWbDbxfOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "f453e7f8-0f66-4b3d-f25f-2ebedf3d8ec9"
      },
      "source": [
        "for x,y in train_it1:\n",
        "  # print(x[0]['context'],y[0])\n",
        "  for i in x[0]['context']:\n",
        "    print(i['body'])\n",
        "\n",
        "  for i in x[0]['choice_list']:\n",
        "    print(i)\n",
        "  break\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bacon bacon bacon salt  table and or sea salt  pepper mortar and pestle food processor containers to hold finished product\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-9f2fbafd9721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choice_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'title'"
          ]
        }
      ]
    }
  ]
}