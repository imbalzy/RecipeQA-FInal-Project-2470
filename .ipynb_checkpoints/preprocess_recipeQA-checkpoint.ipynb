{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/imbalzy/RecipeQA-FInal-Project-2470/blob/main/preprocess_recipeQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lc_xt_0EnLjC",
    "outputId": "00dbfcb6-8ad4-4fe0-b598-6cd88f46bdc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
    "!cp \"/content/gdrive/My Drive/Kaggle/kaggle.json\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZuqEJgQvnOTn",
    "outputId": "3346265f-75c4-4722-c7b0-53fde11eba3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading recipeqa-nlp-dataset.zip to /content\n",
      "100% 2.54G/2.55G [00:37<00:00, 41.6MB/s]\n",
      "100% 2.55G/2.55G [00:37<00:00, 73.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d jeromeblanchet/recipeqa-nlp-dataset\n",
    "!unzip recipeqa-nlp-dataset.zip -d data/ > /dev/null\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DOw7DHwq_Qg7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_file(file_name):\n",
    "  with open(file_name) as f:\n",
    "    data = json.load(f)['data']\n",
    "  textual_cloze = [item for item in data if item[\"task\"]==\"textual_cloze\"]\n",
    "  visual_cloze = [item for item in data if item[\"task\"]==\"visual_cloze\"]\n",
    "  visual_coherence = [item for item in data if item[\"task\"]==\"visual_coherence\"]\n",
    "  visual_ordering = [item for item in data if item[\"task\"]==\"visual_ordering\"]\n",
    "  return textual_cloze, visual_cloze, visual_coherence, visual_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DGsi8uMkB3vJ"
   },
   "outputs": [],
   "source": [
    "def delete_keys(dataset):\n",
    "  if (dataset[0][\"task\"]==\"visual_coherence\"):\n",
    "    [data.pop(\"question\") for data in dataset]\n",
    "  if (dataset[0][\"task\"]==\"visual_ordering\"):\n",
    "    [data.pop(\"question\") for data in dataset]\n",
    "    for data in dataset:\n",
    "      order = data[\"choice_list\"][0]\n",
    "      data[\"image_list\"] = {0:order[0], 1:order[1], 2:order[2], 3:order[3]}\n",
    "      img2ind = {v:k for k,v in data[\"image_list\"].items()}\n",
    "      data[\"choice_list\"]=[[img2ind[img] for img in choice] for choice in data[\"choice_list\"]]\n",
    "  [[data.pop(key,None) for key in [\"context_modality\", \"split\", \"qid\", \"question_modality\", \"task\", \"question_text\"]] for data in dataset]\n",
    "  [[[step.pop(key) for key in [\"id\",\"videos\"]] for step in data['context']] for data in dataset]\n",
    "#  print(json.dumps(dataset[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WHzzLeWAa8bH"
   },
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "# Load image\n",
    "  image = tf.io.decode_jpeg(tf.io.read_file(file_path),channels=3)\n",
    "# Convert image to normalized float [0, 1]\n",
    "  image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "# resize image\n",
    "  image = tf.image.resize(image, [256,256])\n",
    "# Rescale data to range (-1, 1)\n",
    "  image = (image - 0.5) * 2\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9vxBRb4lXzXa"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def data_iter(batch_size, dataset, task, split):\n",
    "  num_input = len(dataset)\n",
    "  np.random.shuffle(dataset)\n",
    "  for i in range(num_input // batch_size):\n",
    "    Xs = deepcopy(dataset[i*batch_size:(i+1)*batch_size])\n",
    "    Ys = [item.pop(\"answer\") for item in Xs]\n",
    "    if task==\"textual_cloze\":\n",
    "      for X in Xs:\n",
    "        for step in X[\"context\"]:\n",
    "          step[\"images\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in step[\"images\"]]\n",
    "    if task==\"visual_cloze\":\n",
    "      for X in Xs:\n",
    "        X[\"choice_list\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in X[\"choice_list\"]]\n",
    "        X[\"question\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) if not item==\"@placeholder\" else \"@placeholder\"  for item in X[\"question\"]]\n",
    "    if task==\"visual_coherence\":\n",
    "      for X in Xs:\n",
    "        X[\"choice_list\"] = [load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+item) for item in X[\"choice_list\"]]\n",
    "    if task==\"visual_ordering\":\n",
    "      for X in Xs:\n",
    "        for k,v in X[\"image_list\"].items():\n",
    "          X[\"image_list\"][k] = load_image(\"data/images/images-qa/\"+split+\"/images-qa/\"+X[\"image_list\"][k])\n",
    "    yield Xs, Ys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path_to_glove_file):\n",
    "  embedding_index = {}\n",
    "  with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "      word, coefs = line.split(maxsplit=1)\n",
    "      coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "      embedding_index[word] = coefs\n",
    "  return embedding_index\n",
    "\n",
    "def get_embedding_layer(voc, embeddings_index embedding_dim = 100):\n",
    "  num_tokens = len(voc) + 2\n",
    "  embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "  for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "  embedding_layer = tf.keras.layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "  )\n",
    "  return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sdayD-JWf_mT"
   },
   "outputs": [],
   "source": [
    "def preprocess(batch_size, split):\n",
    "  textual_cloze, visual_cloze, visual_coherence, visual_ordering=read_file(\"data/\"+split+\" recipeqa.json\")\n",
    "  delete_keys(textual_cloze)\n",
    "  delete_keys(visual_cloze)\n",
    "  delete_keys(visual_coherence)\n",
    "  delete_keys(visual_ordering)\n",
    "  textual_cloze_iter = data_iter(batch_size, textual_cloze, \"textual_cloze\", split)\n",
    "  visual_cloze_iter = data_iter(batch_size, visual_cloze, \"visual_cloze\", split)\n",
    "  visual_coherence_iter = data_iter(batch_size, visual_coherence, \"visual_coherence\", split)\n",
    "  visual_ordering_iter = data_iter(batch_size, visual_ordering, \"visual_ordering\", split)\n",
    "  return textual_cloze_iter, visual_cloze_iter, visual_coherence_iter, visual_ordering_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UhE9wKi1rpt7"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  batch_size = 50\n",
    "  train_it1, train_it2, train_it3, train_it4 = preprocess(batch_size, \"train\")\n",
    "  test_it1, test_it2, test_it3, test_it4 = preprocess(batch_size, \"test\")\n",
    "  val_it1, val_it2, val_it3, val_it4 = preprocess(batch_size, \"val\")\n",
    "  # Usage:\n",
    "  for Xs, Ys in val_it2:\n",
    "    print(json.dumps(Xs[0], indent=4, default=lambda x:\"tf_tensor\"))\n",
    "    print(Ys[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHi57yldxI15",
    "outputId": "52d2dbca-cefe-45cd-f140-a078fc39456c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"recipe_id\": \"the-chefs-spice-caddy\",\n",
      "    \"context\": [\n",
      "        {\n",
      "            \"body\": \"So here's the story. My brother-in-law moved into a new space, and he found that his roommate was woefully lacking spices to cook with.What to do?Well, Christmas was coming, so we decided to help him out.Hook him up with enough spices to rock the kitchen or grill. The idea was to give him 20 spices, and a rack to hold them. We bought 20 spice jars with caps and shaker inserts from Specialty Bottle.Once they arrived, it was time to get busy. Using the bottle as a measuring guide, we went to find some wood.\",\n",
      "            \"title\": \"The Guy Needed Some Spices.\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"Using the bottle, I figured out how many bottles long I wanted and how high. I didn't want it tight-tight, so I left room between each bottle for some rattle room. Also to allow for variances in store bought bottles. He might pick up some \\\"Devil-Ghost-Bum-Burner\\\" spice and want to replace the Arrowroot.You'll notice the grinder wheel. I used that to draw out my curves. Then I drilled some holes for the handle, cut it out with a jigsaw and did some edge work with a router.The plywood is standard 5/8\\\" stuff. It's what I had as scrap. (Reduce, reuse, recycle!)\",\n",
      "            \"title\": \"Cut the Handle Section.\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"Since your bottles may vary in size, I'm not giving exact measurements here. There's some fiddly room.Using the handle as a guide, cut out the bottom, with about an 1/8\\\" oversize all the way around. I did this so that when I notch the sides, the bottom will fit into that notch, adding rigidity. This was a fussy bit. Go slow, test your fits and make sure you're not going to tight. For the bottom material I used some 1/8\\\" Luan, again a scrap piece. The sides are 1/4\\\" plywood. (yes, from the scrap bin)Using the table saw, I cut an 1/8\\\" notch, about 1/8\\\" up the side of 1/4\\\" plywood sides. I ran this cut all the way through, yes it leaves a gap that's visible. No I don't care. We could always fill it with putty! The depth of the notch is only 1/8\\\", or halfway through the plywood. Test fit the bottom, it should be snug, but if it isn't, that's ok, we're going to glue it anyway. But aim for snug.TEST FIT EVERYTHING!\",\n",
      "            \"title\": \"Figure Out the Sides.\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"I clamped things up in stages. First I clamped and glued the box. I didn't use any brads, in fear of firing one crooked and popping it out a side. So the box was clamped and glued and it sat overnight. Next time however, I will use some brads. I have a pneumatic brad gun, and will use brads to hold things together. 1/4\\\" plywood gives me enough room as long as the brad isn't too big.The next day I installed the handle. This I also glued and fired some staples into to help secure it while it dried. I stapled through the sides and a couple through the bottom up. More clamps, then overnight to dry.Then I sanded the whole thing. First 200 grit, and I finished with 600 grit.\",\n",
      "            \"title\": \"Clamp It Up.\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"So into Illustrator!I was going to be using a method I've used in the past, which is to print out a design on a color laser printer, making sure it's reversed, then coating the surface of the project with a Matte Gesso medium, sticking the image side down, letting it dry, then rubbing off the paper.I tell you, the process is a pain, but man I like the results.So what you see here is the images I created in Illustrator printed out. Then carefully cut out. Cut out as much of the paper as you can. Saves on rubbing later. And makes it easier to place.\",\n",
      "            \"title\": \"Time for Some GRAPHICS!\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"Do you know how hard it is to find a water based stain?Not real hard if you know how to look. What I used was Rit\\u00ae clothing dye. Grey.Why not an oil based stain? Because I was using the Gesso over it, I wanted to make sure it stuck, so a water based stain was it. I mixed the Rit\\u00ae dye with water and using a sponge brush, coated the sanded surface.The water did raise the grain a little, so once it was dry, I used a 600 grit paper to knock down the high spots. It gave the finish a nice patina. \",\n",
      "            \"title\": \"Stain the Wood.\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"You can obviously skip this step, and finish the caddy however you wish. Some nice tung oil, or anything really. I prefer oil finishes verses poly finishes. They just feel better over sanded wood. (there's a joke there somewhere)So add a layer of Gesso to the surface, a little thick, but not milky white thick. Then press the paper into the Gesso with the ink side down, and let it dry overnight. The next day, get the paper wet, and start rubbing away the paper. Go easy! the ink is only a couple molecules thick! It's VERY easy to rub through the image. With that said however, I LIKE the look if it's rubbed through in some sections. Instant vintage! I finish the entire caddy with a couple coats of linseed oil. The oil sticks to the Matte Gesso just fine.This thing looks like it has seen trips to the beach and gets loved.\",\n",
      "            \"title\": \"Apply Some GRAPHICS!\"\n",
      "        },\n",
      "        {\n",
      "            \"body\": \"So my wife went to the co-op to get the spices needed. While there, several people asked about the caddy, and where THEY could get one.So I'm back out to the shop making 3 MORE! They want them unfinished so they can do the paint/stain/oil themselves, which is great.The 6oz jars that I bought, are standard spice jars found on the shelves of the store, so people can just buy what they need and mix things up. (Bulk spices however are cheaper) There is enough wiggle room in the caddy to get other jars in there. I just wouldn't force anything as the box will give way. It's built light, because it gets heavy once the spices are added.Not, \\\"It's a workout.\\\" heavy, but enough where you don't want to start out with a lot of weight. Enjoy!\",\n",
      "            \"title\": \"Go Get Some Spices!\"\n",
      "        }\n",
      "    ],\n",
      "    \"choice_list\": [\n",
      "        \"tf_tensor\",\n",
      "        \"tf_tensor\",\n",
      "        \"tf_tensor\",\n",
      "        \"tf_tensor\"\n",
      "    ],\n",
      "    \"question\": [\n",
      "        \"tf_tensor\",\n",
      "        \"tf_tensor\",\n",
      "        \"@placeholder\",\n",
      "        \"tf_tensor\"\n",
      "    ]\n",
      "}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWVcWbDbxfOq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "preprocess-recipeQA",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
