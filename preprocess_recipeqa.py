# -*- coding: utf-8 -*-
"""preprocess-recipeQA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UorKgiZ2vIp6jG57FL_CNbuyDlkFBTw2
"""

# Google Colab setup
"""
from google.colab import drive
drive.mount('/content/gdrive')
import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content"
!cp "/content/gdrive/My Drive/Kaggle/kaggle.json" .

!kaggle datasets download -d jeromeblanchet/recipeqa-nlp-dataset
!unzip recipeqa-nlp-dataset.zip -d data/ > /dev/null
"""

import json
import numpy as np
import tensorflow as tf

def read_file(file_name):
  with open(file_name) as f:
    data = json.load(f)['data']
  textual_cloze = [item for item in data if item["task"]=="textual_cloze"]
  visual_cloze = [item for item in data if item["task"]=="visual_cloze"]
  visual_coherence = [item for item in data if item["task"]=="visual_coherence"]
  visual_ordering = [item for item in data if item["task"]=="visual_ordering"]
  return textual_cloze, visual_cloze, visual_coherence, visual_ordering

def delete_keys(dataset):
  if (dataset[0]["task"]=="visual_coherence"):
    [data.pop("question") for data in dataset]
  if (dataset[0]["task"]=="visual_ordering"):
    [data.pop("question") for data in dataset]
    for data in dataset:
      order = data["choice_list"][0]
      data["image_list"] = {0:order[0], 1:order[1], 2:order[2], 3:order[3]}
      img2ind = {v:k for k,v in data["image_list"].items()}
      data["choice_list"]=[[img2ind[img] for img in choice] for choice in data["choice_list"]]
  [[data.pop(key,None) for key in ["context_modality", "split", "qid", "question_modality", "task", "question_text"]] for data in dataset]
  [[[step.pop(key) for key in ["id","videos"]] for step in data['context']] for data in dataset]
#  print(json.dumps(dataset[0], indent=4))

def load_image(file_path):
# Load image
  image = tf.io.decode_jpeg(tf.io.read_file(file_path),channels=3)
# Convert image to normalized float [0, 1]
  image = tf.image.convert_image_dtype(image,tf.float32)
# resize image
  image = tf.image.resize(image, [256,256])
# Rescale data to range (-1, 1)
  image = (image - 0.5) * 2
  return image

from copy import deepcopy
def data_iter(batch_size, dataset, task, split):
  num_input = len(dataset)
  np.random.shuffle(dataset)
  for i in range(num_input // batch_size):
    Xs = deepcopy(dataset[i*batch_size:(i+1)*batch_size])
    Ys = [item.pop("answer") for item in Xs]
    if task=="textual_cloze":
      for X in Xs:
        for step in X["context"]:
          step["images"] = [load_image("data/images/images-qa/"+split+"/images-qa/"+item) for item in step["images"]]
    if task=="visual_cloze":
      for X in Xs:
        X["choice_list"] = [load_image("data/images/images-qa/"+split+"/images-qa/"+item) for item in X["choice_list"]]
        X["question"] = [load_image("data/images/images-qa/"+split+"/images-qa/"+item) if not item=="@placeholder" else "@placeholder"  for item in X["question"]]
    if task=="visual_coherence":
      for X in Xs:
        X["choice_list"] = [load_image("data/images/images-qa/"+split+"/images-qa/"+item) for item in X["choice_list"]]
    if task=="visual_ordering":
      for X in Xs:
        for k,v in X["image_list"].items():
          X["image_list"][k] = load_image("data/images/images-qa/"+split+"/images-qa/"+X["image_list"][k])
    yield Xs, Ys

def preprocess(batch_size, split):
  textual_cloze, visual_cloze, visual_coherence, visual_ordering=read_file("data/"+split+" recipeqa.json")
  delete_keys(textual_cloze)
  delete_keys(visual_cloze)
  delete_keys(visual_coherence)
  delete_keys(visual_ordering)
  textual_cloze_iter = data_iter(batch_size, textual_cloze, "textual_cloze", split)
  visual_cloze_iter = data_iter(batch_size, visual_cloze, "visual_cloze", split)
  visual_coherence_iter = data_iter(batch_size, visual_coherence, "visual_coherence", split)
  visual_ordering_iter = data_iter(batch_size, visual_ordering, "visual_ordering", split)
  return textual_cloze_iter, visual_cloze_iter, visual_coherence_iter, visual_ordering_iter

# Usage example:
"""
batch_size = 50
train_it1, train_it2, train_it3, train_it4 = preprocess(batch_size, "train")
test_it1, test_it2, test_it3, test_it4 = preprocess(batch_size, "test")
val_it1, val_it2, val_it3, val_it4 = preprocess(batch_size, "val")

for Xs, Ys in val_it2:
  print(json.dumps(Xs[0], indent=4, default=lambda x:"tf_tensor"))
  print(Ys[0])
  break
"""
